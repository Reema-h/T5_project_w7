{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Reema-h/T5_project_w7/blob/main/Task1_CBOW.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L4G-WdYBozAF"
      },
      "source": [
        "# Continuous Bag of Words (CBOW) Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RhS9KCVPpSy2"
      },
      "source": [
        "In this exam, we will create a CBOW model using a sample Arabic traffic corpus. The corpus consists of sentences describing various traffic scenarios. The goal of the CBOW model is to predict a target word based on its surrounding context words."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BmX5AlBspz6g"
      },
      "source": [
        "# Importing Required Libraries"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S6Ba2ibzpydu"
      },
      "source": [
        "In this step, we import the necessary libraries to build and train the Continuous Bag of Words (CBOW) model.\n",
        "\n",
        "- **TensorFlow and Keras**: Used to build the neural network model, including the layers like `Embedding`, `Dense`, and `Lambda`.\n",
        "- **Tokenizer**: A utility from Keras for tokenizing and processing text data.\n",
        "- **NumPy**: Used for handling numerical operations, particularly for processing arrays and data manipulation.\n",
        "\n",
        "These libraries will provide the essential tools for text preprocessing and model development in the upcoming steps.\n",
        "\n",
        "Add more if needed!\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Embedding, Lambda"
      ],
      "metadata": {
        "id": "g-oPA11lEemj"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-LHg8WazpVFL"
      },
      "source": [
        "# Preparing the Corpus"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aXDrgRcvoliV"
      },
      "source": [
        "In this step, we initialize the corpus that will be used for training the Continuous Bag of Words (CBOW) model. The corpus consists of Arabic sentences, each of which describes different traffic scenarios.\n",
        "\n",
        "- **Corpus**: A collection of traffic-related sentences in Arabic.\n",
        "\n",
        "This step sets up the text data that we will use in the upcoming stages of tokenization and model training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "qEQJL-CNjjvO"
      },
      "outputs": [],
      "source": [
        "corpus = [\n",
        "    \"الطريق مزدحم اليوم بسبب الحادث المروري الذي حدث صباحاً ويؤدي إلى تأخير كبير في الوصول\",\n",
        "    \"كان الطريق مزدحما للغاية والسيارات متوقفة تقريباً نتيجة الازدحام الشديد والحركة بطيئة جداً ولا تتحسن\",\n",
        "    \"أنا أحب الذهاب إلى السوق في الصباح الباكر لتفادي الازدحام وشراء الخضروات الطازجة دون الانتظار في الطريق\",\n",
        "    \"السيارات بطيئة بسبب الازدحام المروري في الشارع الرئيسي والتأخير في حركة المرور خلال ساعات الذروة\",\n",
        "    \"هناك ازدحام مروري في الشارع بسبب أعمال البناء والحفريات التي تعطل حركة السيارات وتتسبب في تأخير كبير\",\n",
        "    \"ازدحام السيارات يزداد في المساء عندما يبدأ الجميع بالعودة إلى منازلهم من العمل وتتوقف حركة المرور بالكامل\",\n",
        "    \"الطريق السريع يشهد ازدحاما مستمرا خلال فترة الظهيرة بسبب الشاحنات الكبيرة التي تبطئ حركة السير\",\n",
        "    \"الحافلات والسيارات عالقة في الازدحام المروري في المنطقة التجارية مما يؤدي إلى تأخير وصول الناس إلى وجهاتهم\",\n",
        "    \"حركة المرور مزدحمة اليوم بسبب الفعاليات التي تقام في وسط المدينة مما يزيد من صعوبة الوصول إلى هناك\",\n",
        "    \"كان من الصعب جدا القيادة على الطريق الرئيسي اليوم بسبب الازدحام الخانق الذي استمر طوال اليوم\",\n",
        "    \"الطريق إلى المطار مزدحم اليوم بسبب الحوادث المتكررة والتأخيرات الكبيرة في حركة المرور على الطريق السريع\",\n",
        "    \"الشارع مزدحم بالسيارات والحافلات الكبيرة مما يجعل التنقل بطيئًا جدًا ويزيد من وقت الوصول إلى العمل\",\n",
        "    \"ازدحام السيارات في المدينة أصبح مشكلة كبيرة خاصة خلال ساعات الذروة حيث يصعب التحرك بسرعة\",\n",
        "    \"تفاقم الازدحام في الطرق الجانبية بسبب إغلاق الطريق الرئيسي المؤدي إلى وسط المدينة لصيانة الجسر\",\n",
        "    \"ازدحام مروري خانق يواجه السكان يوميًا خلال تنقلهم من وإلى العمل على الطرق السريعة المؤدية إلى المدينة\",\n",
        "    \"التأخيرات المرورية اليوم ناجمة عن سوء الأحوال الجوية والضباب الذي يعيق الرؤية ويبطئ حركة السيارات\",\n",
        "    \"حوادث السير المتكررة على الطريق الزراعي تؤدي إلى ازدحام مروري شديد وتأخير كبير في وصول السيارات\",\n",
        "    \"كانت حركة السير اليوم غير منتظمة بسبب تنظيم حدث رياضي كبير أدى إلى إغلاق بعض الشوارع الرئيسية\",\n",
        "    \"الأعمال الإنشائية في الشارع الرئيسي تسببت في اختناق مروري كامل وتباطؤ في حركة السيارات خلال النهار\",\n",
        "    \"تراكم السيارات عند تقاطع الطرق الرئيسية أدى إلى ازدحام شديد وزيادة كبيرة في مدة الانتظار للوصول إلى الجهة المطلوبة\"\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TtAp6KPlqBzA"
      },
      "source": [
        "# Defining Vocabulary and Model Parameters"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EOPRl8IfqAHo"
      },
      "source": [
        "In this step, we define key parameters that will be used to configure the CBOW model.\n",
        "\n",
        "- **Vocabulary size**: We calculate the size of the vocabulary based on the number of unique words in the corpus. The `vocab_size` represents the total number of unique tokens (words) in the dataset plus one for padding.\n",
        "  \n",
        "- **Embedding size**: The `embedding_size` defines the dimensionality of the word embeddings. In this case, we set the embedding size to 10, meaning each word will be represented as a 10-dimensional vector in the embedding layer.\n",
        "\n",
        "- **Window size**: The `window_size` defines how many words to the left and right of the target word are considered as context. Here, a window size of 2 means that two words before and two words after the target word will be used as context.\n",
        "\n",
        "These parameters will play an essential role in shaping the CBOW model architecture.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "icwJ4As2qEkP"
      },
      "outputs": [],
      "source": [
        "vocab_size = len(set(\" \".join(corpus).split())) + 1 #unique tokens\n",
        "embedding_size = 10 # vector\n",
        "window_size = 2 #context window size\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w6b35855qQqP"
      },
      "source": [
        "# Preparing Context-Target Pairs for CBOW"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "589xXbYmqEuR"
      },
      "source": [
        "In this step, we generate the context-target pairs from the tokenized sequences to train the CBOW model.\n",
        "\n",
        "- **Context words**: For each word in a sequence, the surrounding words (within the window size) are considered as context. The context consists of the words immediately before and after the target word.\n",
        "  \n",
        "- **Target word**: The word in the middle of the context window is treated as the target word that the model will learn to predict.\n",
        "\n",
        "We iterate through each sequence, collecting the context words and corresponding target words:\n",
        "- For each word in a sequence, we gather the surrounding words based on the defined window size.\n",
        "- The middle word is the target, and the surrounding words form the context.\n",
        "\n",
        "Finally:\n",
        "- **`X`**: An array of context words.\n",
        "- **`y`**: The target words are one-hot encoded, which means they are converted into a categorical format where each word is represented as a vector of length equal to the vocabulary size.\n",
        "\n",
        "These context-target pairs will be used to train the CBOW model to predict a target word based on its context.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(corpus)\n",
        "\n",
        "# convert text to sequences\n",
        "sequences = tokenizer.texts_to_sequences(corpus)\n",
        "\n",
        "\n",
        "tokenized_sequences = [sequence for sequence in sequences if len(sequence) > 0]  # filter empty sequences\n"
      ],
      "metadata": {
        "id": "MrSqs9ErIAIS"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "c8c1MkYOqSfd"
      },
      "outputs": [],
      "source": [
        "def generate_context_target_pairs(sequences, window_size):\n",
        "    X, y = [], []\n",
        "    for sequence in sequences:\n",
        "        for i, word in enumerate(sequence):\n",
        "\n",
        "            start = max(0, i - window_size)\n",
        "            end = min(len(sequence), i + window_size + 1)\n",
        "\n",
        "            context = [sequence[j] for j in range(start, end) if j != i]\n",
        "            target = word\n",
        "\n",
        "            X.append(context)\n",
        "            y.append(target)\n",
        "\n",
        "    return X, y"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X, y = generate_context_target_pairs(tokenized_sequences, window_size)"
      ],
      "metadata": {
        "id": "gnuPFRI0HA-U"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_sequences"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "13eg1oEpJT1y",
        "outputId": "40a9bda4-7d7e-43a7-948b-0570d45acb32"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[3, 19, 7, 4, 47, 20, 21, 30, 48, 49, 2, 22, 12, 1, 23],\n",
              " [31, 3, 50, 51, 32, 52, 53, 54, 8, 55, 56, 33, 57, 58, 59],\n",
              " [60, 61, 62, 2, 63, 1, 64, 65, 66, 8, 67, 68, 69, 70, 34, 1, 3],\n",
              " [6, 33, 4, 8, 20, 1, 13, 14, 71, 1, 5, 15, 10, 35, 36],\n",
              " [37, 9, 16, 1, 13, 4, 72, 73, 74, 24, 75, 5, 6, 76, 1, 22, 12],\n",
              " [9, 6, 77, 1, 78, 79, 80, 81, 82, 2, 83, 11, 25, 84, 5, 15, 85],\n",
              " [3, 38, 86, 87, 88, 10, 89, 90, 4, 91, 26, 24, 92, 5, 27],\n",
              " [93, 32, 94, 1, 8, 20, 1, 95, 96, 28, 97, 2, 22, 39, 98, 2, 99],\n",
              " [5, 15, 100, 7, 4, 101, 24, 102, 1, 40, 17, 28, 103, 11, 104, 23, 2, 37],\n",
              " [31, 11, 105, 106, 107, 18, 3, 14, 7, 4, 8, 108, 21, 109, 110, 7],\n",
              " [3, 2, 111, 19, 7, 4, 112, 41, 113, 26, 1, 5, 15, 18, 3, 38],\n",
              " [13, 19, 114, 115, 26, 28, 116, 117, 118, 119, 120, 11, 121, 23, 2, 25],\n",
              " [9, 6, 1, 17, 122, 123, 42, 124, 10, 35, 36, 125, 126, 127, 128],\n",
              " [129, 8, 1, 29, 130, 4, 43, 3, 14, 131, 2, 40, 17, 132, 133],\n",
              " [9, 16, 134, 135, 136, 137, 10, 138, 11, 139, 25, 18, 29, 140, 141, 2, 17],\n",
              " [142, 143, 7, 144, 145, 146, 147, 148, 149, 21, 150, 151, 152, 5, 6],\n",
              " [153, 27, 41, 18, 3, 154, 155, 2, 9, 16, 44, 156, 12, 1, 39, 6],\n",
              " [157, 5, 27, 7, 158, 159, 4, 160, 30, 161, 12, 45, 2, 43, 162, 163, 46],\n",
              " [164, 165, 1, 13, 14, 166, 1, 167, 16, 168, 169, 1, 5, 6, 10, 170],\n",
              " [171,\n",
              "  6,\n",
              "  172,\n",
              "  173,\n",
              "  29,\n",
              "  46,\n",
              "  45,\n",
              "  2,\n",
              "  9,\n",
              "  44,\n",
              "  174,\n",
              "  42,\n",
              "  1,\n",
              "  175,\n",
              "  34,\n",
              "  176,\n",
              "  2,\n",
              "  177,\n",
              "  178]]"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "r8igVSHCJj4o",
        "outputId": "f9189388-d57d-456c-df0d-02fad63dbfd7"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[19, 7],\n",
              " [3, 7, 4],\n",
              " [3, 19, 4, 47],\n",
              " [19, 7, 47, 20],\n",
              " [7, 4, 20, 21],\n",
              " [4, 47, 21, 30],\n",
              " [47, 20, 30, 48],\n",
              " [20, 21, 48, 49],\n",
              " [21, 30, 49, 2],\n",
              " [30, 48, 2, 22],\n",
              " [48, 49, 22, 12],\n",
              " [49, 2, 12, 1],\n",
              " [2, 22, 1, 23],\n",
              " [22, 12, 23],\n",
              " [12, 1],\n",
              " [3, 50],\n",
              " [31, 50, 51],\n",
              " [31, 3, 51, 32],\n",
              " [3, 50, 32, 52],\n",
              " [50, 51, 52, 53],\n",
              " [51, 32, 53, 54],\n",
              " [32, 52, 54, 8],\n",
              " [52, 53, 8, 55],\n",
              " [53, 54, 55, 56],\n",
              " [54, 8, 56, 33],\n",
              " [8, 55, 33, 57],\n",
              " [55, 56, 57, 58],\n",
              " [56, 33, 58, 59],\n",
              " [33, 57, 59],\n",
              " [57, 58],\n",
              " [61, 62],\n",
              " [60, 62, 2],\n",
              " [60, 61, 2, 63],\n",
              " [61, 62, 63, 1],\n",
              " [62, 2, 1, 64],\n",
              " [2, 63, 64, 65],\n",
              " [63, 1, 65, 66],\n",
              " [1, 64, 66, 8],\n",
              " [64, 65, 8, 67],\n",
              " [65, 66, 67, 68],\n",
              " [66, 8, 68, 69],\n",
              " [8, 67, 69, 70],\n",
              " [67, 68, 70, 34],\n",
              " [68, 69, 34, 1],\n",
              " [69, 70, 1, 3],\n",
              " [70, 34, 3],\n",
              " [34, 1],\n",
              " [33, 4],\n",
              " [6, 4, 8],\n",
              " [6, 33, 8, 20],\n",
              " [33, 4, 20, 1],\n",
              " [4, 8, 1, 13],\n",
              " [8, 20, 13, 14],\n",
              " [20, 1, 14, 71],\n",
              " [1, 13, 71, 1],\n",
              " [13, 14, 1, 5],\n",
              " [14, 71, 5, 15],\n",
              " [71, 1, 15, 10],\n",
              " [1, 5, 10, 35],\n",
              " [5, 15, 35, 36],\n",
              " [15, 10, 36],\n",
              " [10, 35],\n",
              " [9, 16],\n",
              " [37, 16, 1],\n",
              " [37, 9, 1, 13],\n",
              " [9, 16, 13, 4],\n",
              " [16, 1, 4, 72],\n",
              " [1, 13, 72, 73],\n",
              " [13, 4, 73, 74],\n",
              " [4, 72, 74, 24],\n",
              " [72, 73, 24, 75],\n",
              " [73, 74, 75, 5],\n",
              " [74, 24, 5, 6],\n",
              " [24, 75, 6, 76],\n",
              " [75, 5, 76, 1],\n",
              " [5, 6, 1, 22],\n",
              " [6, 76, 22, 12],\n",
              " [76, 1, 12],\n",
              " [1, 22],\n",
              " [6, 77],\n",
              " [9, 77, 1],\n",
              " [9, 6, 1, 78],\n",
              " [6, 77, 78, 79],\n",
              " [77, 1, 79, 80],\n",
              " [1, 78, 80, 81],\n",
              " [78, 79, 81, 82],\n",
              " [79, 80, 82, 2],\n",
              " [80, 81, 2, 83],\n",
              " [81, 82, 83, 11],\n",
              " [82, 2, 11, 25],\n",
              " [2, 83, 25, 84],\n",
              " [83, 11, 84, 5],\n",
              " [11, 25, 5, 15],\n",
              " [25, 84, 15, 85],\n",
              " [84, 5, 85],\n",
              " [5, 15],\n",
              " [38, 86],\n",
              " [3, 86, 87],\n",
              " [3, 38, 87, 88],\n",
              " [38, 86, 88, 10],\n",
              " [86, 87, 10, 89],\n",
              " [87, 88, 89, 90],\n",
              " [88, 10, 90, 4],\n",
              " [10, 89, 4, 91],\n",
              " [89, 90, 91, 26],\n",
              " [90, 4, 26, 24],\n",
              " [4, 91, 24, 92],\n",
              " [91, 26, 92, 5],\n",
              " [26, 24, 5, 27],\n",
              " [24, 92, 27],\n",
              " [92, 5],\n",
              " [32, 94],\n",
              " [93, 94, 1],\n",
              " [93, 32, 1, 8],\n",
              " [32, 94, 8, 20],\n",
              " [94, 1, 20, 1],\n",
              " [1, 8, 1, 95],\n",
              " [8, 20, 95, 96],\n",
              " [20, 1, 96, 28],\n",
              " [1, 95, 28, 97],\n",
              " [95, 96, 97, 2],\n",
              " [96, 28, 2, 22],\n",
              " [28, 97, 22, 39],\n",
              " [97, 2, 39, 98],\n",
              " [2, 22, 98, 2],\n",
              " [22, 39, 2, 99],\n",
              " [39, 98, 99],\n",
              " [98, 2],\n",
              " [15, 100],\n",
              " [5, 100, 7],\n",
              " [5, 15, 7, 4],\n",
              " [15, 100, 4, 101],\n",
              " [100, 7, 101, 24],\n",
              " [7, 4, 24, 102],\n",
              " [4, 101, 102, 1],\n",
              " [101, 24, 1, 40],\n",
              " [24, 102, 40, 17],\n",
              " [102, 1, 17, 28],\n",
              " [1, 40, 28, 103],\n",
              " [40, 17, 103, 11],\n",
              " [17, 28, 11, 104],\n",
              " [28, 103, 104, 23],\n",
              " [103, 11, 23, 2],\n",
              " [11, 104, 2, 37],\n",
              " [104, 23, 37],\n",
              " [23, 2],\n",
              " [11, 105],\n",
              " [31, 105, 106],\n",
              " [31, 11, 106, 107],\n",
              " [11, 105, 107, 18],\n",
              " [105, 106, 18, 3],\n",
              " [106, 107, 3, 14],\n",
              " [107, 18, 14, 7],\n",
              " [18, 3, 7, 4],\n",
              " [3, 14, 4, 8],\n",
              " [14, 7, 8, 108],\n",
              " [7, 4, 108, 21],\n",
              " [4, 8, 21, 109],\n",
              " [8, 108, 109, 110],\n",
              " [108, 21, 110, 7],\n",
              " [21, 109, 7],\n",
              " [109, 110],\n",
              " [2, 111],\n",
              " [3, 111, 19],\n",
              " [3, 2, 19, 7],\n",
              " [2, 111, 7, 4],\n",
              " [111, 19, 4, 112],\n",
              " [19, 7, 112, 41],\n",
              " [7, 4, 41, 113],\n",
              " [4, 112, 113, 26],\n",
              " [112, 41, 26, 1],\n",
              " [41, 113, 1, 5],\n",
              " [113, 26, 5, 15],\n",
              " [26, 1, 15, 18],\n",
              " [1, 5, 18, 3],\n",
              " [5, 15, 3, 38],\n",
              " [15, 18, 38],\n",
              " [18, 3],\n",
              " [19, 114],\n",
              " [13, 114, 115],\n",
              " [13, 19, 115, 26],\n",
              " [19, 114, 26, 28],\n",
              " [114, 115, 28, 116],\n",
              " [115, 26, 116, 117],\n",
              " [26, 28, 117, 118],\n",
              " [28, 116, 118, 119],\n",
              " [116, 117, 119, 120],\n",
              " [117, 118, 120, 11],\n",
              " [118, 119, 11, 121],\n",
              " [119, 120, 121, 23],\n",
              " [120, 11, 23, 2],\n",
              " [11, 121, 2, 25],\n",
              " [121, 23, 25],\n",
              " [23, 2],\n",
              " [6, 1],\n",
              " [9, 1, 17],\n",
              " [9, 6, 17, 122],\n",
              " [6, 1, 122, 123],\n",
              " [1, 17, 123, 42],\n",
              " [17, 122, 42, 124],\n",
              " [122, 123, 124, 10],\n",
              " [123, 42, 10, 35],\n",
              " [42, 124, 35, 36],\n",
              " [124, 10, 36, 125],\n",
              " [10, 35, 125, 126],\n",
              " [35, 36, 126, 127],\n",
              " [36, 125, 127, 128],\n",
              " [125, 126, 128],\n",
              " [126, 127],\n",
              " [8, 1],\n",
              " [129, 1, 29],\n",
              " [129, 8, 29, 130],\n",
              " [8, 1, 130, 4],\n",
              " [1, 29, 4, 43],\n",
              " [29, 130, 43, 3],\n",
              " [130, 4, 3, 14],\n",
              " [4, 43, 14, 131],\n",
              " [43, 3, 131, 2],\n",
              " [3, 14, 2, 40],\n",
              " [14, 131, 40, 17],\n",
              " [131, 2, 17, 132],\n",
              " [2, 40, 132, 133],\n",
              " [40, 17, 133],\n",
              " [17, 132],\n",
              " [16, 134],\n",
              " [9, 134, 135],\n",
              " [9, 16, 135, 136],\n",
              " [16, 134, 136, 137],\n",
              " [134, 135, 137, 10],\n",
              " [135, 136, 10, 138],\n",
              " [136, 137, 138, 11],\n",
              " [137, 10, 11, 139],\n",
              " [10, 138, 139, 25],\n",
              " [138, 11, 25, 18],\n",
              " [11, 139, 18, 29],\n",
              " [139, 25, 29, 140],\n",
              " [25, 18, 140, 141],\n",
              " [18, 29, 141, 2],\n",
              " [29, 140, 2, 17],\n",
              " [140, 141, 17],\n",
              " [141, 2],\n",
              " [143, 7],\n",
              " [142, 7, 144],\n",
              " [142, 143, 144, 145],\n",
              " [143, 7, 145, 146],\n",
              " [7, 144, 146, 147],\n",
              " [144, 145, 147, 148],\n",
              " [145, 146, 148, 149],\n",
              " [146, 147, 149, 21],\n",
              " [147, 148, 21, 150],\n",
              " [148, 149, 150, 151],\n",
              " [149, 21, 151, 152],\n",
              " [21, 150, 152, 5],\n",
              " [150, 151, 5, 6],\n",
              " [151, 152, 6],\n",
              " [152, 5],\n",
              " [27, 41],\n",
              " [153, 41, 18],\n",
              " [153, 27, 18, 3],\n",
              " [27, 41, 3, 154],\n",
              " [41, 18, 154, 155],\n",
              " [18, 3, 155, 2],\n",
              " [3, 154, 2, 9],\n",
              " [154, 155, 9, 16],\n",
              " [155, 2, 16, 44],\n",
              " [2, 9, 44, 156],\n",
              " [9, 16, 156, 12],\n",
              " [16, 44, 12, 1],\n",
              " [44, 156, 1, 39],\n",
              " [156, 12, 39, 6],\n",
              " [12, 1, 6],\n",
              " [1, 39],\n",
              " [5, 27],\n",
              " [157, 27, 7],\n",
              " [157, 5, 7, 158],\n",
              " [5, 27, 158, 159],\n",
              " [27, 7, 159, 4],\n",
              " [7, 158, 4, 160],\n",
              " [158, 159, 160, 30],\n",
              " [159, 4, 30, 161],\n",
              " [4, 160, 161, 12],\n",
              " [160, 30, 12, 45],\n",
              " [30, 161, 45, 2],\n",
              " [161, 12, 2, 43],\n",
              " [12, 45, 43, 162],\n",
              " [45, 2, 162, 163],\n",
              " [2, 43, 163, 46],\n",
              " [43, 162, 46],\n",
              " [162, 163],\n",
              " [165, 1],\n",
              " [164, 1, 13],\n",
              " [164, 165, 13, 14],\n",
              " [165, 1, 14, 166],\n",
              " [1, 13, 166, 1],\n",
              " [13, 14, 1, 167],\n",
              " [14, 166, 167, 16],\n",
              " [166, 1, 16, 168],\n",
              " [1, 167, 168, 169],\n",
              " [167, 16, 169, 1],\n",
              " [16, 168, 1, 5],\n",
              " [168, 169, 5, 6],\n",
              " [169, 1, 6, 10],\n",
              " [1, 5, 10, 170],\n",
              " [5, 6, 170],\n",
              " [6, 10],\n",
              " [6, 172],\n",
              " [171, 172, 173],\n",
              " [171, 6, 173, 29],\n",
              " [6, 172, 29, 46],\n",
              " [172, 173, 46, 45],\n",
              " [173, 29, 45, 2],\n",
              " [29, 46, 2, 9],\n",
              " [46, 45, 9, 44],\n",
              " [45, 2, 44, 174],\n",
              " [2, 9, 174, 42],\n",
              " [9, 44, 42, 1],\n",
              " [44, 174, 1, 175],\n",
              " [174, 42, 175, 34],\n",
              " [42, 1, 34, 176],\n",
              " [1, 175, 176, 2],\n",
              " [175, 34, 2, 177],\n",
              " [34, 176, 177, 178],\n",
              " [176, 2, 178],\n",
              " [2, 177]]"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "CGQfFDA0JlVQ",
        "outputId": "3efef064-7472-4fc6-cf32-4511a88b46bb"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[3,\n",
              " 19,\n",
              " 7,\n",
              " 4,\n",
              " 47,\n",
              " 20,\n",
              " 21,\n",
              " 30,\n",
              " 48,\n",
              " 49,\n",
              " 2,\n",
              " 22,\n",
              " 12,\n",
              " 1,\n",
              " 23,\n",
              " 31,\n",
              " 3,\n",
              " 50,\n",
              " 51,\n",
              " 32,\n",
              " 52,\n",
              " 53,\n",
              " 54,\n",
              " 8,\n",
              " 55,\n",
              " 56,\n",
              " 33,\n",
              " 57,\n",
              " 58,\n",
              " 59,\n",
              " 60,\n",
              " 61,\n",
              " 62,\n",
              " 2,\n",
              " 63,\n",
              " 1,\n",
              " 64,\n",
              " 65,\n",
              " 66,\n",
              " 8,\n",
              " 67,\n",
              " 68,\n",
              " 69,\n",
              " 70,\n",
              " 34,\n",
              " 1,\n",
              " 3,\n",
              " 6,\n",
              " 33,\n",
              " 4,\n",
              " 8,\n",
              " 20,\n",
              " 1,\n",
              " 13,\n",
              " 14,\n",
              " 71,\n",
              " 1,\n",
              " 5,\n",
              " 15,\n",
              " 10,\n",
              " 35,\n",
              " 36,\n",
              " 37,\n",
              " 9,\n",
              " 16,\n",
              " 1,\n",
              " 13,\n",
              " 4,\n",
              " 72,\n",
              " 73,\n",
              " 74,\n",
              " 24,\n",
              " 75,\n",
              " 5,\n",
              " 6,\n",
              " 76,\n",
              " 1,\n",
              " 22,\n",
              " 12,\n",
              " 9,\n",
              " 6,\n",
              " 77,\n",
              " 1,\n",
              " 78,\n",
              " 79,\n",
              " 80,\n",
              " 81,\n",
              " 82,\n",
              " 2,\n",
              " 83,\n",
              " 11,\n",
              " 25,\n",
              " 84,\n",
              " 5,\n",
              " 15,\n",
              " 85,\n",
              " 3,\n",
              " 38,\n",
              " 86,\n",
              " 87,\n",
              " 88,\n",
              " 10,\n",
              " 89,\n",
              " 90,\n",
              " 4,\n",
              " 91,\n",
              " 26,\n",
              " 24,\n",
              " 92,\n",
              " 5,\n",
              " 27,\n",
              " 93,\n",
              " 32,\n",
              " 94,\n",
              " 1,\n",
              " 8,\n",
              " 20,\n",
              " 1,\n",
              " 95,\n",
              " 96,\n",
              " 28,\n",
              " 97,\n",
              " 2,\n",
              " 22,\n",
              " 39,\n",
              " 98,\n",
              " 2,\n",
              " 99,\n",
              " 5,\n",
              " 15,\n",
              " 100,\n",
              " 7,\n",
              " 4,\n",
              " 101,\n",
              " 24,\n",
              " 102,\n",
              " 1,\n",
              " 40,\n",
              " 17,\n",
              " 28,\n",
              " 103,\n",
              " 11,\n",
              " 104,\n",
              " 23,\n",
              " 2,\n",
              " 37,\n",
              " 31,\n",
              " 11,\n",
              " 105,\n",
              " 106,\n",
              " 107,\n",
              " 18,\n",
              " 3,\n",
              " 14,\n",
              " 7,\n",
              " 4,\n",
              " 8,\n",
              " 108,\n",
              " 21,\n",
              " 109,\n",
              " 110,\n",
              " 7,\n",
              " 3,\n",
              " 2,\n",
              " 111,\n",
              " 19,\n",
              " 7,\n",
              " 4,\n",
              " 112,\n",
              " 41,\n",
              " 113,\n",
              " 26,\n",
              " 1,\n",
              " 5,\n",
              " 15,\n",
              " 18,\n",
              " 3,\n",
              " 38,\n",
              " 13,\n",
              " 19,\n",
              " 114,\n",
              " 115,\n",
              " 26,\n",
              " 28,\n",
              " 116,\n",
              " 117,\n",
              " 118,\n",
              " 119,\n",
              " 120,\n",
              " 11,\n",
              " 121,\n",
              " 23,\n",
              " 2,\n",
              " 25,\n",
              " 9,\n",
              " 6,\n",
              " 1,\n",
              " 17,\n",
              " 122,\n",
              " 123,\n",
              " 42,\n",
              " 124,\n",
              " 10,\n",
              " 35,\n",
              " 36,\n",
              " 125,\n",
              " 126,\n",
              " 127,\n",
              " 128,\n",
              " 129,\n",
              " 8,\n",
              " 1,\n",
              " 29,\n",
              " 130,\n",
              " 4,\n",
              " 43,\n",
              " 3,\n",
              " 14,\n",
              " 131,\n",
              " 2,\n",
              " 40,\n",
              " 17,\n",
              " 132,\n",
              " 133,\n",
              " 9,\n",
              " 16,\n",
              " 134,\n",
              " 135,\n",
              " 136,\n",
              " 137,\n",
              " 10,\n",
              " 138,\n",
              " 11,\n",
              " 139,\n",
              " 25,\n",
              " 18,\n",
              " 29,\n",
              " 140,\n",
              " 141,\n",
              " 2,\n",
              " 17,\n",
              " 142,\n",
              " 143,\n",
              " 7,\n",
              " 144,\n",
              " 145,\n",
              " 146,\n",
              " 147,\n",
              " 148,\n",
              " 149,\n",
              " 21,\n",
              " 150,\n",
              " 151,\n",
              " 152,\n",
              " 5,\n",
              " 6,\n",
              " 153,\n",
              " 27,\n",
              " 41,\n",
              " 18,\n",
              " 3,\n",
              " 154,\n",
              " 155,\n",
              " 2,\n",
              " 9,\n",
              " 16,\n",
              " 44,\n",
              " 156,\n",
              " 12,\n",
              " 1,\n",
              " 39,\n",
              " 6,\n",
              " 157,\n",
              " 5,\n",
              " 27,\n",
              " 7,\n",
              " 158,\n",
              " 159,\n",
              " 4,\n",
              " 160,\n",
              " 30,\n",
              " 161,\n",
              " 12,\n",
              " 45,\n",
              " 2,\n",
              " 43,\n",
              " 162,\n",
              " 163,\n",
              " 46,\n",
              " 164,\n",
              " 165,\n",
              " 1,\n",
              " 13,\n",
              " 14,\n",
              " 166,\n",
              " 1,\n",
              " 167,\n",
              " 16,\n",
              " 168,\n",
              " 169,\n",
              " 1,\n",
              " 5,\n",
              " 6,\n",
              " 10,\n",
              " 170,\n",
              " 171,\n",
              " 6,\n",
              " 172,\n",
              " 173,\n",
              " 29,\n",
              " 46,\n",
              " 45,\n",
              " 2,\n",
              " 9,\n",
              " 44,\n",
              " 174,\n",
              " 42,\n",
              " 1,\n",
              " 175,\n",
              " 34,\n",
              " 176,\n",
              " 2,\n",
              " 177,\n",
              " 178]"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# One-hot encode\n",
        "\"\"\"tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(y)\n",
        "y_encoded = tokenizer.texts_to_matrix(y, mode='binary')\"\"\"\n",
        "#ERROR --> AttributeError: 'int' object has no attribute 'lower'\n",
        "\n",
        "# solve error\n",
        "tokenizer = Tokenizer()\n",
        "y = [str(i) for i in y] # int to string\n",
        "tokenizer.fit_on_texts(y)\n",
        "y_encoded = tokenizer.texts_to_matrix(y, mode='binary')"
      ],
      "metadata": {
        "id": "pElzuP-jIn83"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hgxmB4fZqU1A"
      },
      "source": [
        "# Building and Training the CBOW Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QkXe33DgqSvD"
      },
      "source": [
        "In this step, we build and train the Continuous Bag of Words (CBOW) model using the context-target pairs created earlier.\n",
        "\n",
        "1. **Model architecture**:\n",
        "   - **Embedding layer**: This layer transforms the input context words into dense vector representations (embeddings) of size defined by `embedding_size`. The `input_dim` is set to the vocabulary size, and the `input_length` is twice the window size (since context consists of words from both sides of the target).\n",
        "   \n",
        "   - **Lambda layer**: This layer computes the mean of the context word embeddings. It averages the embeddings of the context words to generate a single representation that will be used to predict the target word.\n",
        "   \n",
        "   - **Dense layer**: This fully connected layer outputs a probability distribution over the vocabulary, using the softmax activation function. It predicts the most likely target word based on the context word embeddings.\n",
        "\n",
        "2. **Compilation**:\n",
        "   The model is compiled using the Adam optimizer and categorical cross-entropy as the loss function, which is suitable for multi-class classification tasks. Accuracy is used as a metric to evaluate the model's performance during training.\n",
        "\n",
        "3. **Training the model**:\n",
        "   The model is trained on the context-target pairs for 500 epochs. During each epoch, the model learns to predict the target word based on the context, refining its weights to improve accuracy.\n",
        "\n",
        "4. **Saving the model weights**:\n",
        "   After training, the model weights are saved to a file (`cbow_model.weights.h5`) for future use. This allows us to load the trained model later without retraining.\n",
        "\n",
        "By the end of this step, the CBOW model will have learned to predict target words based on their surrounding context from the given corpus."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "vL3UZZe3qhhh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "23506972-4b8c-4733-d305-8a0e7f147808"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "model = Sequential([\n",
        "    Dense(embedding_size, input_shape=(2 * window_size,)),\n",
        "    Embedding(input_dim= vocab_size, output_dim= embedding_size, input_length=2 * window_size),\n",
        "    Lambda(lambda x: tf.reduce_mean(x, axis=1)), # calculate the avr\n",
        "    Dense(vocab_size, activation='softmax')\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "_9I8XT01OlFV",
        "outputId": "94ea72b1-04fc-4467-daa8-b26d662b393c"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_2\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)                  │              \u001b[38;5;34m50\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ embedding_2 (\u001b[38;5;33mEmbedding\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m10\u001b[0m)              │           \u001b[38;5;34m1,790\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lambda_2 (\u001b[38;5;33mLambda\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m179\u001b[0m)                 │           \u001b[38;5;34m1,969\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)                  │              <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ embedding_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,790</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lambda_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">179</span>)                 │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,969</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m3,809\u001b[0m (14.88 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,809</span> (14.88 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m3,809\u001b[0m (14.88 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,809</span> (14.88 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "fAOM04AXMnoD"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X, y_encoded, epochs=5, verbose=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 426
        },
        "collapsed": true,
        "id": "JVUvpuc3sYa-",
        "outputId": "f1139b8f-e521-4258-8a7a-1a77e6552d8b"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Unrecognized data type: x=[[19, 7], [3, 7, 4], [3, 19, 4, 47], [19, 7, 47, 20], [7, 4, 20, 21], [4, 47, 21, 30], [47, 20, 30, 48], [20, 21, 48, 49], [21, 30, 49, 2], [30, 48, 2, 22], [48, 49, 22, 12], [49, 2, 12, 1], [2, 22, 1, 23], [22, 12, 23], [12, 1], [3, 50], [31, 50, 51], [31, 3, 51, 32], [3, 50, 32, 52], [50, 51, 52, 53], [51, 32, 53, 54], [32, 52, 54, 8], [52, 53, 8, 55], [53, 54, 55, 56], [54, 8, 56, 33], [8, 55, 33, 57], [55, 56, 57, 58], [56, 33, 58, 59], [33, 57, 59], [57, 58], [61, 62], [60, 62, 2], [60, 61, 2, 63], [61, 62, 63, 1], [62, 2, 1, 64], [2, 63, 64, 65], [63, 1, 65, 66], [1, 64, 66, 8], [64, 65, 8, 67], [65, 66, 67, 68], [66, 8, 68, 69], [8, 67, 69, 70], [67, 68, 70, 34], [68, 69, 34, 1], [69, 70, 1, 3], [70, 34, 3], [34, 1], [33, 4], [6, 4, 8], [6, 33, 8, 20], [33, 4, 20, 1], [4, 8, 1, 13], [8, 20, 13, 14], [20, 1, 14, 71], [1, 13, 71, 1], [13, 14, 1, 5], [14, 71, 5, 15], [71, 1, 15, 10], [1, 5, 10, 35], [5, 15, 35, 36], [15, 10, 36], [10, 35], [9, 16], [37, 16, 1], [37, 9, 1, 13], [9, 16, 13, 4], [16, 1, 4, 72], [1, 13, 72, 73], [13, 4, 73, 74], [4, 72, 74, 24], [72, 73, 24, 75], [73, 74, 75, 5], [74, 24, 5, 6], [24, 75, 6, 76], [75, 5, 76, 1], [5, 6, 1, 22], [6, 76, 22, 12], [76, 1, 12], [1, 22], [6, 77], [9, 77, 1], [9, 6, 1, 78], [6, 77, 78, 79], [77, 1, 79, 80], [1, 78, 80, 81], [78, 79, 81, 82], [79, 80, 82, 2], [80, 81, 2, 83], [81, 82, 83, 11], [82, 2, 11, 25], [2, 83, 25, 84], [83, 11, 84, 5], [11, 25, 5, 15], [25, 84, 15, 85], [84, 5, 85], [5, 15], [38, 86], [3, 86, 87], [3, 38, 87, 88], [38, 86, 88, 10], [86, 87, 10, 89], [87, 88, 89, 90], [88, 10, 90, 4], [10, 89, 4, 91], [89, 90, 91, 26], [90, 4, 26, 24], [4, 91, 24, 92], [91, 26, 92, 5], [26, 24, 5, 27], [24, 92, 27], [92, 5], [32, 94], [93, 94, 1], [93, 32, 1, 8], [32, 94, 8, 20], [94, 1, 20, 1], [1, 8, 1, 95], [8, 20, 95, 96], [20, 1, 96, 28], [1, 95, 28, 97], [95, 96, 97, 2], [96, 28, 2, 22], [28, 97, 22, 39], [97, 2, 39, 98], [2, 22, 98, 2], [22, 39, 2, 99], [39, 98, 99], [98, 2], [15, 100], [5, 100, 7], [5, 15, 7, 4], [15, 100, 4, 101], [100, 7, 101, 24], [7, 4, 24, 102], [4, 101, 102, 1], [101, 24, 1, 40], [24, 102, 40, 17], [102, 1, 17, 28], [1, 40, 28, 103], [40, 17, 103, 11], [17, 28, 11, 104], [28, 103, 104, 23], [103, 11, 23, 2], [11, 104, 2, 37], [104, 23, 37], [23, 2], [11, 105], [31, 105, 106], [31, 11, 106, 107], [11, 105, 107, 18], [105, 106, 18, 3], [106, 107, 3, 14], [107, 18, 14, 7], [18, 3, 7, 4], [3, 14, 4, 8], [14, 7, 8, 108], [7, 4, 108, 21], [4, 8, 21, 109], [8, 108, 109, 110], [108, 21, 110, 7], [21, 109, 7], [109, 110], [2, 111], [3, 111, 19], [3, 2, 19, 7], [2, 111, 7, 4], [111, 19, 4, 112], [19, 7, 112, 41], [7, 4, 41, 113], [4, 112, 113, 26], [112, 41, 26, 1], [41, 113, 1, 5], [113, 26, 5, 15], [26, 1, 15, 18], [1, 5, 18, 3], [5, 15, 3, 38], [15, 18, 38], [18, 3], [19, 114], [13, 114, 115], [13, 19, 115, 26], [19, 114, 26, 28], [114, 115, 28, 116], [115, 26, 116, 117], [26, 28, 117, 118], [28, 116, 118, 119], [116, 117, 119, 120], [117, 118, 120, 11], [118, 119, 11, 121], [119, 120, 121, 23], [120, 11, 23, 2], [11, 121, 2, 25], [121, 23, 25], [23, 2], [6, 1], [9, 1, 17], [9, 6, 17, 122], [6, 1, 122, 123], [1, 17, 123, 42], [17, 122, 42, 124], [122, 123, 124, 10], [123, 42, 10, 35], [42, 124, 35, 36], [124, 10, 36, 125], [10, 35, 125, 126], [35, 36, 126, 127], [36, 125, 127, 128], [125, 126, 128], [126, 127], [8, 1], [129, 1, 29], [129, 8, 29, 130], [8, 1, 130, 4], [1, 29, 4, 43], [29, 130, 43, 3], [130, 4, 3, 14], [4, 43, 14, 131], [43, 3, 131, 2], [3, 14, 2, 40], [14, 131, 40, 17], [131, 2, 17, 132], [2, 40, 132, 133], [40, 17, 133], [17, 132], [16, 134], [9, 134, 135], [9, 16, 135, 136], [16, 134, 136, 137], [134, 135, 137, 10], [135, 136, 10, 138], [136, 137, 138, 11], [137, 10, 11, 139], [10, 138, 139, 25], [138, 11, 25, 18], [11, 139, 18, 29], [139, 25, 29, 140], [25, 18, 140, 141], [18, 29, 141, 2], [29, 140, 2, 17], [140, 141, 17], [141, 2], [143, 7], [142, 7, 144], [142, 143, 144, 145], [143, 7, 145, 146], [7, 144, 146, 147], [144, 145, 147, 148], [145, 146, 148, 149], [146, 147, 149, 21], [147, 148, 21, 150], [148, 149, 150, 151], [149, 21, 151, 152], [21, 150, 152, 5], [150, 151, 5, 6], [151, 152, 6], [152, 5], [27, 41], [153, 41, 18], [153, 27, 18, 3], [27, 41, 3, 154], [41, 18, 154, 155], [18, 3, 155, 2], [3, 154, 2, 9], [154, 155, 9, 16], [155, 2, 16, 44], [2, 9, 44, 156], [9, 16, 156, 12], [16, 44, 12, 1], [44, 156, 1, 39], [156, 12, 39, 6], [12, 1, 6], [1, 39], [5, 27], [157, 27, 7], [157, 5, 7, 158], [5, 27, 158, 159], [27, 7, 159, 4], [7, 158, 4, 160], [158, 159, 160, 30], [159, 4, 30, 161], [4, 160, 161, 12], [160, 30, 12, 45], [30, 161, 45, 2], [161, 12, 2, 43], [12, 45, 43, 162], [45, 2, 162, 163], [2, 43, 163, 46], [43, 162, 46], [162, 163], [165, 1], [164, 1, 13], [164, 165, 13, 14], [165, 1, 14, 166], [1, 13, 166, 1], [13, 14, 1, 167], [14, 166, 167, 16], [166, 1, 16, 168], [1, 167, 168, 169], [167, 16, 169, 1], [16, 168, 1, 5], [168, 169, 5, 6], [169, 1, 6, 10], [1, 5, 10, 170], [5, 6, 170], [6, 10], [6, 172], [171, 172, 173], [171, 6, 173, 29], [6, 172, 29, 46], [172, 173, 46, 45], [173, 29, 45, 2], [29, 46, 2, 9], [46, 45, 9, 44], [45, 2, 44, 174], [2, 9, 174, 42], [9, 44, 42, 1], [44, 174, 1, 175], [174, 42, 175, 34], [42, 1, 34, 176], [1, 175, 176, 2], [175, 34, 2, 177], [34, 176, 177, 178], [176, 2, 178], [2, 177]] (of type <class 'list'>)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-51-a81232c27750>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_encoded\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;31m# `keras.config.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/trainers/data_adapters/__init__.py\u001b[0m in \u001b[0;36mget_data_adapter\u001b[0;34m(x, y, sample_weight, batch_size, steps_per_epoch, shuffle, class_weight)\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0;31m# )\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Unrecognized data type: x={x} (of type {type(x)})\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Unrecognized data type: x=[[19, 7], [3, 7, 4], [3, 19, 4, 47], [19, 7, 47, 20], [7, 4, 20, 21], [4, 47, 21, 30], [47, 20, 30, 48], [20, 21, 48, 49], [21, 30, 49, 2], [30, 48, 2, 22], [48, 49, 22, 12], [49, 2, 12, 1], [2, 22, 1, 23], [22, 12, 23], [12, 1], [3, 50], [31, 50, 51], [31, 3, 51, 32], [3, 50, 32, 52], [50, 51, 52, 53], [51, 32, 53, 54], [32, 52, 54, 8], [52, 53, 8, 55], [53, 54, 55, 56], [54, 8, 56, 33], [8, 55, 33, 57], [55, 56, 57, 58], [56, 33, 58, 59], [33, 57, 59], [57, 58], [61, 62], [60, 62, 2], [60, 61, 2, 63], [61, 62, 63, 1], [62, 2, 1, 64], [2, 63, 64, 65], [63, 1, 65, 66], [1, 64, 66, 8], [64, 65, 8, 67], [65, 66, 67, 68], [66, 8, 68, 69], [8, 67, 69, 70], [67, 68, 70, 34], [68, 69, 34, 1], [69, 70, 1, 3], [70, 34, 3], [34, 1], [33, 4], [6, 4, 8], [6, 33, 8, 20], [33, 4, 20, 1], [4, 8, 1, 13], [8, 20, 13, 14], [20, 1, 14, 71], [1, 13, 71, 1], [13, 14, 1, 5], [14, 71, 5, 15], [71, 1, 15, 10], [1, 5, 10, 35], [5, 15, 35, 36], [15, 10, 36], [10, 35], [9, 16], [37, 16, 1], [37, 9, 1, 13], [9, 16, 13, 4], [16, 1, 4, 72], [1, 13, 72, 73], [13, 4, 73, 74], [4, 72, 74, 24], [72, 73, 24, 75], [73, 74, 75, 5], [74, 24, 5, 6], [24, 75, 6, 76], [75, 5, 76, 1], [5, 6, 1, 22], [6, 76, 22, 12], [76, 1, 12], [1, 22], [6, 77], [9, 77, 1], [9, 6, 1, 78], [6, 77, 78, 79], [77, 1, 79, 80], [1, 78, 80, 81], [78, 79, 81, 82], [79, 80, 82, 2], [80, 81, 2, 83], [81, 82, 83, 11], [82, 2, 11, 25], [2, 83, 25, 84], [83, 11, 84, 5], [11, 25, 5, 15], [25, 8..."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(np.array(X), np.array(y_encoded), epochs=5, verbose=1)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "ylXTFSzDpydH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_padded = tf.keras.preprocessing.sequence.pad_sequences(X, padding=\"post\")\n",
        "y_padded = tf.keras.preprocessing.sequence.pad_sequences(y_encoded, padding=\"post\")\n",
        "\n",
        "\n",
        "model.fit(np.array(X_padded), np.array(y_padded), epochs=5, verbose=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "id": "fv-anh0ipUNA",
        "outputId": "bf2997c6-8a92-454b-bdaf-bbd43462067c"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/optimizers/base_optimizer.py:664: UserWarning: Gradients do not exist for variables ['kernel', 'bias'] when minimizing the loss. If using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "InvalidArgumentError",
          "evalue": "Graph execution error:\n\nDetected at node sequential_2_1/embedding_2_1/GatherV2 defined at (most recent call last):\n  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n\n  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n\n  File \"/usr/local/lib/python3.10/dist-packages/colab_kernel_launcher.py\", line 37, in <module>\n\n  File \"/usr/local/lib/python3.10/dist-packages/traitlets/config/application.py\", line 992, in launch_instance\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelapp.py\", line 619, in start\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/platform/asyncio.py\", line 195, in start\n\n  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n\n  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 1909, in _run_once\n\n  File \"/usr/lib/python3.10/asyncio/events.py\", line 80, in _run\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/ioloop.py\", line 685, in <lambda>\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/ioloop.py\", line 738, in _run_callback\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 825, in inner\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 786, in run\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 361, in process_one\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 261, in dispatch_shell\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 539, in execute_request\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py\", line 302, in do_execute\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/zmqshell.py\", line 539, in run_cell\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2975, in run_cell\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3030, in _run_cell\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/async_helpers.py\", line 78, in _pseudo_sync_runner\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3257, in run_cell_async\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3473, in run_ast_nodes\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n\n  File \"<ipython-input-52-9b4d7aa8ff7f>\", line 5, in <cell line: 5>\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/backend/tensorflow/trainer.py\", line 318, in fit\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/backend/tensorflow/trainer.py\", line 121, in one_step_on_iterator\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/backend/tensorflow/trainer.py\", line 108, in one_step_on_data\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/backend/tensorflow/trainer.py\", line 51, in train_step\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py\", line 882, in __call__\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/ops/operation.py\", line 46, in __call__\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 156, in error_handler\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/models/sequential.py\", line 209, in call\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/models/functional.py\", line 175, in call\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/ops/function.py\", line 171, in _run_through_graph\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/models/functional.py\", line 556, in call\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py\", line 882, in __call__\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/ops/operation.py\", line 46, in __call__\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 156, in error_handler\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/embedding.py\", line 140, in call\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/ops/numpy.py\", line 4875, in take\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/backend/tensorflow/numpy.py\", line 1951, in take\n\nindices[3,1] = -16 is not in [0, 179)\n\t [[{{node sequential_2_1/embedding_2_1/GatherV2}}]] [Op:__inference_one_step_on_iterator_4090]",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-52-9b4d7aa8ff7f>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_padded\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_padded\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;31m# `keras.config.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     54\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nDetected at node sequential_2_1/embedding_2_1/GatherV2 defined at (most recent call last):\n  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n\n  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n\n  File \"/usr/local/lib/python3.10/dist-packages/colab_kernel_launcher.py\", line 37, in <module>\n\n  File \"/usr/local/lib/python3.10/dist-packages/traitlets/config/application.py\", line 992, in launch_instance\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelapp.py\", line 619, in start\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/platform/asyncio.py\", line 195, in start\n\n  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n\n  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 1909, in _run_once\n\n  File \"/usr/lib/python3.10/asyncio/events.py\", line 80, in _run\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/ioloop.py\", line 685, in <lambda>\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/ioloop.py\", line 738, in _run_callback\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 825, in inner\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 786, in run\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 361, in process_one\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 261, in dispatch_shell\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 539, in execute_request\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py\", line 302, in do_execute\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/zmqshell.py\", line 539, in run_cell\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2975, in run_cell\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3030, in _run_cell\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/async_helpers.py\", line 78, in _pseudo_sync_runner\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3257, in run_cell_async\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3473, in run_ast_nodes\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n\n  File \"<ipython-input-52-9b4d7aa8ff7f>\", line 5, in <cell line: 5>\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/backend/tensorflow/trainer.py\", line 318, in fit\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/backend/tensorflow/trainer.py\", line 121, in one_step_on_iterator\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/backend/tensorflow/trainer.py\", line 108, in one_step_on_data\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/backend/tensorflow/trainer.py\", line 51, in train_step\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py\", line 882, in __call__\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/ops/operation.py\", line 46, in __call__\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 156, in error_handler\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/models/sequential.py\", line 209, in call\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/models/functional.py\", line 175, in call\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/ops/function.py\", line 171, in _run_through_graph\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/models/functional.py\", line 556, in call\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py\", line 882, in __call__\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/ops/operation.py\", line 46, in __call__\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 156, in error_handler\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/embedding.py\", line 140, in call\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/ops/numpy.py\", line 4875, in take\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/backend/tensorflow/numpy.py\", line 1951, in take\n\nindices[3,1] = -16 is not in [0, 179)\n\t [[{{node sequential_2_1/embedding_2_1/GatherV2}}]] [Op:__inference_one_step_on_iterator_4090]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save_weights('cbow_model.weights.h5')"
      ],
      "metadata": {
        "id": "OgAQXmKPLVrx"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mLodiHWkqaL4"
      },
      "source": [
        "# Predicting a Word Using the Trained CBOW Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_SRP_chYqYKS"
      },
      "source": [
        "In this step, we define a function to predict a word based on a given context using the trained CBOW model.\n",
        "\n",
        "1. **Function: `predict_word`**:\n",
        "   - **Input**: The function takes a list of context words as input. The number of context words should match the expected size (2 times the window size).\n",
        "   - **Context sequence conversion**: The input context words are tokenized into a sequence of integers using the same tokenizer that was used during training.\n",
        "   - **Input validation**: The function checks whether the length of the context sequence matches the expected size (2 times the window size). If not, it prints an error message.\n",
        "   - **Prediction**: The tokenized context is fed into the trained CBOW model, which predicts the probability distribution over the vocabulary.\n",
        "   - **Retrieve predicted word**: The predicted word is the one with the highest probability. The function retrieves the word corresponding to the predicted index from the tokenizer's word index.\n",
        "\n",
        "2. **Example**:\n",
        "   - We provide a sample context: `['الحادث', 'بسبب', 'مزدحم', 'الطريق']`.\n",
        "   - The function predicts the word that fits best in this context, based on the model's learned weights.\n",
        "   - The predicted word is printed along with the input context.\n",
        "\n",
        "This function allows us to test the CBOW model by predicting words based on their surrounding context from the corpus."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ykhSWJY0qgCI"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}